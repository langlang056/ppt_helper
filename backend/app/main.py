"""PPT Helper - FastAPI åç«¯"""
import os
import asyncio
import base64
import io
from pathlib import Path
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from contextlib import asynccontextmanager
import json

from app.config import get_settings
from app.models.database import init_db, get_db, AsyncSessionLocal
from app.models.schemas import (
    UploadResponse, PageExplanation, PageContent, KeyPoint,
    PageExplanationMarkdown, ProcessingProgress
)
from app.services.pdf_parser import pdf_parser
from app.services.cache_service import cache_service
from app.services.llm_service import llm_service, create_llm_service

settings = get_settings()

# å­˜å‚¨æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
processing_tasks = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """å¯åŠ¨/å…³é—­ç”Ÿå‘½å‘¨æœŸ"""
    await init_db()
    Path(settings.upload_dir).mkdir(exist_ok=True)
    Path(settings.temp_dir).mkdir(exist_ok=True)
    print(f"âœ… æ•°æ®åº“å·²åˆå§‹åŒ–")
    print(f"âœ… ä¸Šä¼ ç›®å½•: {settings.upload_dir}")
    yield
    print("ğŸ‘‹ å…³é—­æœåŠ¡")


app = FastAPI(title="PPT Helper API", version="0.4.0", lifespan=lifespan)

# CORS é…ç½®ï¼šæ”¯æŒå¼€å‘ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:3001",
        # ç”Ÿäº§ç¯å¢ƒéœ€è¦æ·»åŠ ä½ çš„æœåŠ¡å™¨åœ°å€ï¼Œå¦‚:
        # "http://192.168.1.100",
        # "http://yourdomain.com",
        "*"  # å¼€å‘æ—¶ä½¿ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    return {"message": "PPT Helper API", "version": "0.4.0", "status": "running"}


async def process_pdf_background(
    pdf_id: str,
    file_path: str,
    page_numbers: list[int],
    llm_config: dict = None
):
    """åå°ä»»åŠ¡ï¼šæŒ‰é¡ºåºå¤„ç†æŒ‡å®šé¡µé¢

    Args:
        pdf_id: PDF æ–‡æ¡£ ID
        file_path: PDF æ–‡ä»¶è·¯å¾„
        page_numbers: è¦å¤„ç†çš„é¡µç åˆ—è¡¨
        llm_config: LLM é…ç½® {"api_key": "...", "model": "..."}
    """
    total_pages_to_process = len(page_numbers)
    print(f"ğŸš€ å¼€å§‹åå°å¤„ç† PDF: {pdf_id}, å¤„ç† {total_pages_to_process} é¡µ: {page_numbers}")

    # åˆ›å»º LLM æœåŠ¡å®ä¾‹
    if llm_config and llm_config.get("api_key"):
        current_llm = create_llm_service(
            api_key=llm_config["api_key"],
            model=llm_config.get("model", "gemini-2.5-flash")
        )
        print(f"  ğŸ“¡ ä½¿ç”¨å®¢æˆ·ç«¯ API Keyï¼Œæ¨¡å‹: {llm_config.get('model', 'gemini-2.5-flash')}")
    else:
        # å‘åå…¼å®¹ï¼šä½¿ç”¨å…¨å±€é…ç½®
        current_llm = llm_service
        print(f"  ğŸ“¡ ä½¿ç”¨æœåŠ¡å™¨é»˜è®¤é…ç½®")

    try:
        async with AsyncSessionLocal() as db:
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await cache_service.update_processing_status(db, pdf_id, "processing", 0)

        processed_count = 0
        for page_number in page_numbers:
            print(f"ğŸ“„ å¤„ç†ç¬¬ {page_number} é¡µ ({processed_count + 1}/{total_pages_to_process})...")

            try:
                async with AsyncSessionLocal() as db:
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜
                    cached = await cache_service.get_cached_markdown_explanation(db, pdf_id, page_number)
                    if cached:
                        print(f"âœ… ç¬¬ {page_number} é¡µå·²æœ‰ç¼“å­˜ï¼Œè·³è¿‡")
                        processed_count += 1
                        await cache_service.update_processing_status(db, pdf_id, "processing", processed_count)
                        continue

                # æå–é¡µé¢å›¾åƒ
                print(f"  ğŸ“¸ æå–é¡µé¢å›¾åƒ...")
                page_image = await pdf_parser.parse_single_page(file_path, page_number)

                async with AsyncSessionLocal() as db:
                    # è·å–å‰é¢é¡µé¢çš„æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡
                    previous_summaries = await cache_service.get_previous_summaries(
                        db, pdf_id, page_number, max_pages=3
                    )

                # è°ƒç”¨ LLM ç”Ÿæˆè§£é‡Š
                print(f"  ğŸ¤– è°ƒç”¨ LLM åˆ†æ...")
                markdown_content = await current_llm.analyze_image(
                    image=page_image,
                    page_num=page_number,
                    previous_summaries=previous_summaries,
                    temperature=0.7,
                    max_tokens=4000,
                )

                # æå–æ‘˜è¦
                summary = current_llm.extract_summary(markdown_content, page_number)
                
                async with AsyncSessionLocal() as db:
                    # ä¿å­˜åˆ°ç¼“å­˜
                    await cache_service.save_markdown_explanation(
                        db, pdf_id, page_number, markdown_content, summary
                    )
                    
                    # æ›´æ–°è¿›åº¦
                    processed_count += 1
                    await cache_service.update_processing_status(db, pdf_id, "processing", processed_count)
                
                print(f"âœ… ç¬¬ {page_number} é¡µå¤„ç†å®Œæˆ")
                
                # å°å»¶è¿Ÿé¿å… API é™æµ
                await asyncio.sleep(1)
                
            except Exception as e:
                import traceback
                print(f"âŒ å¤„ç†ç¬¬ {page_number} é¡µå¤±è´¥: {str(e)}")
                print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€é¡µ
                continue
        
        # å¤„ç†å®Œæˆ
        async with AsyncSessionLocal() as db:
            await cache_service.update_processing_status(db, pdf_id, "completed", processed_count)
        print(f"ğŸ‰ PDF {pdf_id} é€‰å®šé¡µé¢å…¨éƒ¨å¤„ç†å®Œæˆ ({processed_count}/{total_pages_to_process})")
        
    except Exception as e:
        import traceback
        print(f"âŒ åå°å¤„ç†å¤±è´¥: {str(e)}")
        print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        try:
            async with AsyncSessionLocal() as db:
                await cache_service.update_processing_status(db, pdf_id, "failed", 0)
        except:
            pass
    finally:
        # æ¸…ç†ä»»åŠ¡è®°å½•
        if pdf_id in processing_tasks:
            del processing_tasks[pdf_id]


@app.post("/api/upload", response_model=UploadResponse)
async def upload_pdf(
    file: UploadFile = File(...), 
    db: AsyncSession = Depends(get_db)
):
    """ä¸Šä¼ å¹¶è§£æ PDFï¼Œå¯åŠ¨åå°å¤„ç†"""
    if not file.filename.endswith(".pdf"):
        raise HTTPException(400, "ä»…æ”¯æŒ PDF æ–‡ä»¶")

    content = await file.read()
    if len(content) / (1024 * 1024) > settings.max_file_size_mb:
        raise HTTPException(400, f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§ {settings.max_file_size_mb}MB")

    temp_path = Path(settings.temp_dir) / file.filename
    with open(temp_path, "wb") as f:
        f.write(content)

    try:
        pdf_id = pdf_parser._generate_pdf_id(str(temp_path))

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if await cache_service.check_pdf_exists(db, pdf_id):
            pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
            if temp_path.exists():
                temp_path.unlink()
            if pdf_doc:
                return UploadResponse(
                    pdf_id=pdf_id,
                    total_pages=pdf_doc.total_pages,
                    filename=file.filename,
                    message="PDF å·²å­˜åœ¨ç¼“å­˜ä¸­",
                )
            else:
                # PDF å­˜åœ¨ä½†å…ƒæ•°æ®ä¸¢å¤±ï¼Œé‡æ–°å¤„ç†
                pass

        # ç§»åŠ¨åˆ°æ°¸ä¹…å­˜å‚¨
        final_path = Path(settings.upload_dir) / f"{pdf_id}.pdf"
        if final_path.exists():
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if temp_path.exists():
                temp_path.unlink()
        else:
            temp_path.rename(final_path)

        total_pages = pdf_parser.get_page_count(str(final_path))

        await cache_service.save_pdf_metadata(
            db, pdf_id, file.filename, total_pages, str(final_path)
        )

        # ä¸å†è‡ªåŠ¨å¯åŠ¨åå°å¤„ç†ï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨è§¦å‘
        return UploadResponse(
            pdf_id=pdf_id, 
            total_pages=total_pages, 
            filename=file.filename,
            message="PDF å·²ä¸Šä¼ ï¼Œè¯·é€‰æ‹©é¡µç åå¼€å§‹åˆ†æ"
        )

    except Exception as e:
        if temp_path.exists():
            temp_path.unlink()
        raise HTTPException(500, f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@app.post("/api/process/{pdf_id}")
async def start_processing(
    pdf_id: str, 
    request: dict,
    db: AsyncSession = Depends(get_db)
):
    """å¯åŠ¨å¤„ç†æŒ‡å®šé¡µç """
    # è·å– PDF å…ƒæ•°æ®
    pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
    if not pdf_doc:
        raise HTTPException(404, "PDF æœªæ‰¾åˆ°")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨å¤„ç†ä¸­ï¼ˆä¸”ä»»åŠ¡ä»åœ¨è¿è¡Œï¼‰
    if pdf_id in processing_tasks:
        task = processing_tasks[pdf_id]
        if not task.done():
            raise HTTPException(400, "è¯¥ PDF æ­£åœ¨å¤„ç†ä¸­")
        else:
            # ä»»åŠ¡å·²å®Œæˆï¼Œæ¸…ç†è®°å½•
            del processing_tasks[pdf_id]
    
    # è·å–è¦å¤„ç†çš„é¡µç åˆ—è¡¨
    page_numbers = request.get("page_numbers", [])
    if not page_numbers:
        raise HTTPException(400, "è¯·æä¾›è¦å¤„ç†çš„é¡µç åˆ—è¡¨")

    # è·å– LLM é…ç½®ï¼ˆå¯é€‰ï¼‰
    llm_config = request.get("llm_config", None)
    if llm_config:
        # éªŒè¯ LLM é…ç½®
        if not llm_config.get("api_key"):
            raise HTTPException(400, "è¯·æä¾›æœ‰æ•ˆçš„ API Key")
        model = llm_config.get("model", "gemini-2.5-flash")
        if model not in ["gemini-2.5-flash", "gemini-2.5-pro"]:
            raise HTTPException(400, f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}")

    # éªŒè¯é¡µç 
    total_pages = pdf_doc.total_pages
    invalid_pages = [p for p in page_numbers if p < 1 or p > total_pages]
    if invalid_pages:
        raise HTTPException(400, f"é¡µç æ— æ•ˆ: {invalid_pages}ï¼Œæœ‰æ•ˆèŒƒå›´: 1-{total_pages}")

    # æ›´æ–°é€‰å®šé¡µæ•°
    async with AsyncSessionLocal() as update_db:
        from sqlalchemy import update
        from app.models.database import PDFDocument
        stmt = update(PDFDocument).where(PDFDocument.id == pdf_id).values(
            selected_pages_count=len(page_numbers),
            processed_pages=0,
            processing_status="pending"
        )
        await update_db.execute(stmt)
        await update_db.commit()

    # å¯åŠ¨åå°å¤„ç†ä»»åŠ¡ï¼ˆä¼ é€’ LLM é…ç½®ï¼‰
    task = asyncio.create_task(
        process_pdf_background(pdf_id, pdf_doc.file_path, page_numbers, llm_config)
    )
    processing_tasks[pdf_id] = task

    return {
        "message": f"å·²å¯åŠ¨å¤„ç† {len(page_numbers)} é¡µ",
        "page_numbers": page_numbers,
        "model": llm_config.get("model", "default") if llm_config else "server_default"
    }


@app.get("/api/progress/{pdf_id}", response_model=ProcessingProgress)
async def get_progress(pdf_id: str, db: AsyncSession = Depends(get_db)):
    """è·å– PDF å¤„ç†è¿›åº¦"""
    pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
    if not pdf_doc:
        raise HTTPException(404, "PDF æœªæ‰¾åˆ°")

    # ä½¿ç”¨é€‰å®šé¡µæ•°è®¡ç®—è¿›åº¦ï¼Œå¦‚æœæ²¡æœ‰é€‰å®šåˆ™ä½¿ç”¨æ€»é¡µæ•°
    total_for_progress = pdf_doc.selected_pages_count if pdf_doc.selected_pages_count > 0 else pdf_doc.total_pages
    progress_percentage = (pdf_doc.processed_pages / total_for_progress * 100) if total_for_progress > 0 else 0

    return ProcessingProgress(
        pdf_id=pdf_id,
        total_pages=total_for_progress,  # è¿”å›é€‰å®šçš„é¡µæ•°
        processed_pages=pdf_doc.processed_pages,
        status=pdf_doc.processing_status or "pending",
        progress_percentage=round(progress_percentage, 1)
    )


@app.get("/api/explain/{pdf_id}/{page_number}", response_model=PageExplanationMarkdown)
async def get_explanation(pdf_id: str, page_number: int, db: AsyncSession = Depends(get_db)):
    """è·å–é¡µé¢ AI è§£é‡Šï¼ˆMarkdown æ ¼å¼ï¼‰"""
    pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
    if not pdf_doc:
        raise HTTPException(404, "PDF æœªæ‰¾åˆ°")

    if not (1 <= page_number <= pdf_doc.total_pages):
        raise HTTPException(400, f"é¡µç æ— æ•ˆï¼ŒèŒƒå›´: 1-{pdf_doc.total_pages}")

    # å°è¯•ä»ç¼“å­˜è·å–
    cached = await cache_service.get_cached_markdown_explanation(db, pdf_id, page_number)
    if cached:
        return cached

    # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè¯´æ˜åå°ä»»åŠ¡è¿˜æ²¡å¤„ç†åˆ°è¿™ä¸€é¡µ
    # è¿”å›ä¸€ä¸ªå¤„ç†ä¸­çš„æç¤º
    return PageExplanationMarkdown(
        page_number=page_number,
        markdown_content="â³ **æ­£åœ¨ç”Ÿæˆä¸­...**\n\nè¯¥é¡µé¢æ­£åœ¨åå°å¤„ç†ä¸­ï¼Œè¯·ç¨å€™åˆ·æ–°ã€‚",
        summary=""
    )


@app.get("/api/download/{pdf_id}")
async def download_markdown(pdf_id: str, db: AsyncSession = Depends(get_db)):
    """ä¸‹è½½å®Œæ•´çš„ Markdown æ–‡ä»¶ï¼ˆåŒ…å«é¡µé¢æˆªå›¾ï¼‰"""
    pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
    if not pdf_doc:
        raise HTTPException(404, "PDF æœªæ‰¾åˆ°")

    if pdf_doc.processing_status != "completed":
        raise HTTPException(400, f"PDF å°šæœªå¤„ç†å®Œæˆï¼Œå½“å‰çŠ¶æ€: {pdf_doc.processing_status}")

    # è·å–æ‰€æœ‰è§£é‡Š
    explanations = await cache_service.get_all_explanations(db, pdf_id)
    
    if not explanations:
        raise HTTPException(404, "æœªæ‰¾åˆ°ä»»ä½•è§£é‡Šå†…å®¹")

    # ç”Ÿæˆ Markdown å†…å®¹
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    md_content = f"""# è¯¾ä»¶è®²è§£: {pdf_doc.filename}

> ç”Ÿæˆæ—¶é—´: {timestamp}
> æ€»é¡µæ•°: {pdf_doc.total_pages}

---

"""
    
    for explanation in explanations:
        page_num = explanation.page_number
        
        # è·å–é¡µé¢å›¾åƒå¹¶è½¬ä¸º base64
        try:
            page_image = await pdf_parser.parse_single_page(pdf_doc.file_path, page_num)
            
            # è½¬æ¢ä¸º base64
            img_buffer = io.BytesIO()
            page_image.save(img_buffer, format='PNG')
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            
            md_content += f"""## ç¬¬ {page_num} é¡µ

![ç¬¬{page_num}é¡µ](data:image/png;base64,{img_base64})

{explanation.explanation_json}

---

"""
        except Exception as e:
            print(f"âš ï¸ è·å–ç¬¬ {page_num} é¡µå›¾åƒå¤±è´¥: {str(e)}")
            md_content += f"""## ç¬¬ {page_num} é¡µ

{explanation.explanation_json}

---

"""
    
    # æ·»åŠ é¡µè„š
    md_content += f"""
## æ–‡æ¡£è¯´æ˜

- æœ¬æ–‡æ¡£ç”± PDF è¯¾ä»¶è‡ªåŠ¨è®²è§£ç³»ç»Ÿç”Ÿæˆ
- æ¯é¡µå†…å®¹åŒ…å«è¯¾ä»¶æˆªå›¾å’Œ AI è¯¦ç»†è®²è§£
- å»ºè®®ç»“åˆåŸå§‹è¯¾ä»¶ä¸€èµ·å­¦ä¹ 

---
*Generated by PPT Helper*
"""
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{Path(pdf_doc.filename).stem}_explained.md"
    
    # è¿”å›æ–‡ä»¶æµ
    return StreamingResponse(
        io.BytesIO(md_content.encode('utf-8')),
        media_type="text/markdown",
        headers={
            "Content-Disposition": f'attachment; filename="{filename}"'
        }
    )


@app.get("/api/pdf/{pdf_id}/info")
async def get_pdf_info(pdf_id: str, db: AsyncSession = Depends(get_db)):
    """è·å– PDF å…ƒæ•°æ®"""
    pdf_doc = await cache_service.get_pdf_metadata(db, pdf_id)
    if not pdf_doc:
        raise HTTPException(404, "PDF æœªæ‰¾åˆ°")

    return {
        "pdf_id": pdf_doc.id,
        "filename": pdf_doc.filename,
        "total_pages": pdf_doc.total_pages,
        "uploaded_at": pdf_doc.uploaded_at.isoformat(),
        "processing_status": pdf_doc.processing_status,
        "processed_pages": pdf_doc.processed_pages,
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app.main:app", host=settings.host, port=settings.port, reload=settings.debug)
